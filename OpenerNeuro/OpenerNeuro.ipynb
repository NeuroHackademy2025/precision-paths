{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was made with the help of AI tools, including ChatGPT and GitHub Copilot.\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the latest version of a given OpenNueo datsey\n",
    "def get_latest_snapshot(dataset_id: str):\n",
    "    \"\"\"\n",
    "    Fetch the latest snapshot tag for a given OpenNeuro dataset ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_id : str\n",
    "        The OpenNeuro dataset ID (e.g., \"ds000001\").\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The latest snapshot tag (version) for the dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    graphql_url = \"https://openneuro.org/crn/graphql\" # GraphQL endpoint for OpenNeuro\n",
    "    \n",
    "    # GraphQL query to fetch dataset snapshots\n",
    "    query = \"\"\"\n",
    "      query ($id: ID!) {\n",
    "        dataset(id: $id) {\n",
    "          snapshots {\n",
    "            tag\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    # Make the GraphQL request to fetch snapshots\n",
    "    res = requests.post(graphql_url, json={\"query\": query, \"variables\": {\"id\": dataset_id}})\n",
    "    res.raise_for_status() # Check for HTTP errors\n",
    "    snaps = res.json()[\"data\"][\"dataset\"][\"snapshots\"] # Extract snapshots\n",
    "    if not snaps: # Check if there are any snapshots\n",
    "        raise Exception(\"No snapshots found.\")\n",
    "    latest = sorted([s[\"tag\"] for s in snaps], reverse=True)[0] # Get the latest tag\n",
    "    return latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get the urls of all JSON files for a specific version of an OpenNeuro dataset\n",
    "# def get_json_urls(dataset_id: str, version_tag: str):\n",
    "#     \"\"\"\n",
    "#     Fetch URLs of JSON files for a specific version of an OpenNeuro dataset.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataset_id : str\n",
    "#         The OpenNeuro dataset ID (e.g., \"ds000001\").\n",
    "#     version_tag : str\n",
    "#         The version tag (snapshot) to fetch JSON files from.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dict\n",
    "#         A dictionary mapping JSON filenames to their download URLs.\n",
    "#     \"\"\"\n",
    "\n",
    "#     graphql_url = \"https://openneuro.org/crn/graphql\" # GraphQL endpoint for OpenNeuro\n",
    "\n",
    "#     # GraphQL query to fetch files for a specific snapshot\n",
    "#     query = \"\"\"\n",
    "#       query ($id: ID!, $tag: String!) {\n",
    "#         snapshot(datasetId: $id, tag: $tag) {\n",
    "#             files {\n",
    "#             filename\n",
    "#             urls\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Make the GraphQL request to fetch files for the specified snapshot\n",
    "#     res = requests.post(graphql_url, json={\"query\": query, \"variables\": {\"id\": dataset_id, \"tag\": version_tag}})\n",
    "#     if res.status_code != 200: # Check for HTTP errors\n",
    "#         print(\"Response content:\\n\", res.text)\n",
    "#         raise Exception(f\"GraphQL error fetching version {version_tag}: {res.status_code}\")\n",
    "#     files = res.json()[\"data\"][\"snapshot\"][\"files\"]\n",
    "    \n",
    "#     # Recursively collect all .json files\n",
    "#     def collect_json_files(directory, current_path=\"\"):\n",
    "#         jsons = {}\n",
    "#         for f in directory.get(\"files\", []):\n",
    "#             if f[\"filename\"].endswith(\".json\"):\n",
    "#                 full_path = f\"{current_path}{f['filename']}\"\n",
    "#                 jsons[full_path] = f[\"urls\"][0]\n",
    "#         for subdir in directory.get(\"directories\", []):\n",
    "#             sub_path = f\"{current_path}{subdir['name']}/\"\n",
    "#             jsons.update(collect_json_files(subdir, sub_path))\n",
    "#         return jsons\n",
    "    \n",
    "#     json_files = {f[\"filename\"]: f[\"urls\"][0] for f in files if f[\"filename\"].endswith(\".json\")}\n",
    "\n",
    "#     print(f\"Found {len(json_files)} JSON files.\")\n",
    "#     print(\"Examples:\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\" --\", example)\n",
    "\n",
    "#     return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_json_urls(dataset_id: str, version_tag: str):\n",
    "#     \"\"\"\n",
    "#     Fetch URLs of all JSON files for a specific version of an OpenNeuro dataset.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataset_id : str\n",
    "#         The OpenNeuro dataset ID (e.g., \"ds000001\").\n",
    "#     version_tag : str\n",
    "#         The version tag (snapshot) to fetch JSON files from.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dict\n",
    "#         A dictionary mapping JSON file paths (with folders) to their download URLs.\n",
    "#     \"\"\"\n",
    "\n",
    "#     graphql_url = \"https://openneuro.org/crn/graphql\"\n",
    "\n",
    "#     query = \"\"\"\n",
    "#     query ($id: ID!, $tag: String!) {\n",
    "#       snapshot(datasetId: $id, tag: $tag) {\n",
    "#         files {\n",
    "#           filename\n",
    "#           urls\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "#     \"\"\"\n",
    "\n",
    "#     res = requests.post(graphql_url, json={\"query\": query, \"variables\": {\"id\": dataset_id, \"tag\": version_tag}})\n",
    "#     if res.status_code != 200:\n",
    "#         print(\"Response content:\\n\", res.text)\n",
    "#         raise Exception(f\"GraphQL error fetching version {version_tag}: {res.status_code}\")\n",
    "\n",
    "#     files = res.json()[\"data\"][\"snapshot\"][\"files\"]\n",
    "\n",
    "#     # Filter for JSON files and map full path -> first url\n",
    "#     json_files = {f[\"filename\"]: f[\"urls\"][0] for f in files if f[\"filename\"].endswith(\".json\")}\n",
    "\n",
    "#     print(f\"✅ Found {len(json_files)} JSON files.\")\n",
    "#     print(\"Examples:\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\"  -\", example)\n",
    "\n",
    "#     return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# def get_json_urls(dataset_id: str, version_tag: str):\n",
    "#     \"\"\"\n",
    "#     Fetch all JSON files (including nested) for a given dataset and version using the OpenNeuro REST API manifest.\n",
    "\n",
    "#     Returns dict mapping full path -> URL\n",
    "#     \"\"\"\n",
    "#     manifest_url = f\"https://openneuro.org/crn/datasets/{dataset_id}/snapshots/{version_tag}/contents\"\n",
    "\n",
    "#     res = requests.get(manifest_url)\n",
    "#     res.raise_for_status()\n",
    "\n",
    "#     contents = res.json()  # This is a list of file/directory dicts recursively\n",
    "\n",
    "#     json_files = {}\n",
    "\n",
    "#     def recurse_files(entries, prefix=\"\"):\n",
    "#         for entry in entries:\n",
    "#             if entry[\"type\"] == \"file\" and entry[\"name\"].endswith(\".json\"):\n",
    "#                 path = prefix + entry[\"name\"]\n",
    "#                 # The URL is in 's3Uri' or 'url' or build from key? Let's check:\n",
    "#                 # Try 'url' field if present, else construct from s3Uri\n",
    "#                 url = entry.get(\"url\")\n",
    "#                 if not url:\n",
    "#                     url = f\"https://s3.amazonaws.com/openneuro.org/{dataset_id}/{path}\"\n",
    "#                 json_files[path] = url\n",
    "#             elif entry[\"type\"] == \"directory\":\n",
    "#                 recurse_files(entry[\"contents\"], prefix + entry[\"name\"] + \"/\")\n",
    "\n",
    "#     recurse_files(contents)\n",
    "\n",
    "#     print(f\"✅ Found {len(json_files)} JSON files.\")\n",
    "#     print(\"Examples:\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\" -\", example)\n",
    "\n",
    "#     return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# def list_s3_json_files(dataset_id):\n",
    "#     s3 = boto3.client('s3')\n",
    "#     bucket = 'openneuro.org'\n",
    "#     prefix = f\"{dataset_id}/\"\n",
    "\n",
    "#     paginator = s3.get_paginator('list_objects_v2')\n",
    "#     pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "#     json_files = {}\n",
    "\n",
    "#     for page in pages:\n",
    "#         for obj in page.get('Contents', []):\n",
    "#             key = obj['Key']\n",
    "#             if key.endswith('.json'):\n",
    "#                 url = f\"https://s3.amazonaws.com/{bucket}/{key}\"\n",
    "#                 json_files[key] = url\n",
    "\n",
    "#     print(f\"Found {len(json_files)} JSON files.\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\" -\", example)\n",
    "\n",
    "#     return json_files\n",
    "\n",
    "# json_urls = list_s3_json_files('ds005264')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_json_files(dataset_id):\n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    bucket = 'openneuro.org'\n",
    "    prefix = f\"{dataset_id}/\"\n",
    "\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "    json_files = {}\n",
    "\n",
    "    for page in pages:\n",
    "        for obj in page.get('Contents', []):\n",
    "            key = obj['Key']\n",
    "            if key.endswith('.json'):\n",
    "                url = f\"https://s3.amazonaws.com/{bucket}/{key}\"\n",
    "                json_files[key] = url\n",
    "\n",
    "    print(f\"Found {len(json_files)} JSON files.\")\n",
    "    for example in list(json_files.keys())[:10]:\n",
    "        print(\" -\", example)\n",
    "\n",
    "    return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# flatten json objects into a single-level dictionary\n",
    "def flatten_json(y):\n",
    "    \"\"\"\n",
    "    Flatten a nested JSON object into a single-level dictionary with dot notation keys.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : dict\n",
    "        The nested JSON object to flatten.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A flattened dictionary with keys in dot notation.\n",
    "    \"\"\"\n",
    "\n",
    "    out = {} # Initialize output dictionary\n",
    "\n",
    "    # Recursive function to flatten the JSON\n",
    "    def _flatten(x, name=\"\"):\n",
    "        if isinstance(x, dict):\n",
    "            for k,v in x.items():\n",
    "                _flatten(v, name + k + \".\")\n",
    "        elif isinstance(x, list):\n",
    "            for i,v in enumerate(x):\n",
    "                _flatten(v, name + str(i) + \".\")\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "    _flatten(y)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load JSON files from an OpenNeuro dataset URL into a Pandas DataFrame\n",
    "# def jsons_to_dataframe(openneuro_url: str):\n",
    "#     \"\"\"\n",
    "#     Load JSON files from an OpenNeuro dataset URL into a Pandas DataFrame.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     openneuro_url : str\n",
    "#         The OpenNeuro dataset URL (e.g., \"https://openneuro.org/datasets/ds000001/versions/1.0.0\").\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         A Pandas DataFrame containing the flattened JSON data, indexed by file name.\n",
    "#     \"\"\"\n",
    "\n",
    "#     parsed = urlparse(openneuro_url)\n",
    "#     parts = parsed.path.strip(\"/\").split(\"/\")\n",
    "#     dataset_id = parts[1]\n",
    "#     version = parts[3] if len(parts) > 3 and parts[2] == \"versions\" else None\n",
    "\n",
    "#     if version is None:\n",
    "#         version = get_latest_snapshot(dataset_id) #######\n",
    "#         print(f\"No version specified — using latest: {version}\")\n",
    "#     else:\n",
    "#         print(f\"Using specified version: {version}\")\n",
    "\n",
    "#     json_urls = get_json_urls(dataset_id, version) #######\n",
    "#     print(f\"Found {len(json_urls)} JSON files for version {version}\")\n",
    "\n",
    "#     records = []\n",
    "#     for fname, url in tqdm(json_urls.items(), desc=\"Downloading JSONs\"):\n",
    "#         r = requests.get(url)\n",
    "#         r.raise_for_status()\n",
    "#         flat = flatten_json(r.json()) #######\n",
    "#         flat[\"__file__\"] = fname\n",
    "#         records.append(flat)\n",
    "\n",
    "#     df = pd.DataFrame(records).set_index(\"__file__\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsons_to_dataframe(openneuro_url: str):\n",
    "    \"\"\"\n",
    "    Load JSON files from an OpenNeuro dataset URL into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    openneuro_url : str\n",
    "        The OpenNeuro dataset URL (e.g., \"https://openneuro.org/datasets/ds000001/versions/1.0.0\").\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A Pandas DataFrame containing the flattened JSON data, indexed by file name.\n",
    "    \"\"\"\n",
    "\n",
    "    parsed = urlparse(openneuro_url)\n",
    "    parts = parsed.path.strip(\"/\").split(\"/\")\n",
    "    dataset_id = parts[1]\n",
    "    # version is not used for S3 listing, so no need to parse it here\n",
    "\n",
    "    print(f\"Listing JSON files for dataset: {dataset_id} from S3 (no versioning)\")\n",
    "\n",
    "    # Call your S3 JSON file lister WITHOUT version arg\n",
    "    json_urls = list_s3_json_files(dataset_id)  # <-- Removed version argument here\n",
    "\n",
    "    print(f\"Found {len(json_urls)} JSON files.\")\n",
    "\n",
    "    records = []\n",
    "    for fname, url in tqdm(json_urls.items(), desc=\"Downloading JSONs\"):\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        flat = flatten_json(r.json())\n",
    "        flat[\"__file__\"] = fname\n",
    "        records.append(flat)\n",
    "\n",
    "    df = pd.DataFrame(records).set_index(\"__file__\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_json_urls(\"ds005264\", \"1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 296 JSON files.\n",
      " - ds005264/dataset_description.json\n",
      " - ds005264/participants.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-1_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-2_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-3_T1w.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-AP_epi.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-PA_epi.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_bold.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_sbref.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-2_bold.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "json_urls = list_s3_json_files('ds005264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing JSON files for dataset: ds005264 from S3 (no versioning)\n",
      "Found 296 JSON files.\n",
      " - ds005264/dataset_description.json\n",
      " - ds005264/participants.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-1_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-2_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-3_T1w.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-AP_epi.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-PA_epi.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_bold.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_sbref.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-2_bold.json\n",
      "Found 296 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading JSONs: 100%|██████████| 296/296 [01:19<00:00,  3.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>BIDSVersion</th>\n",
       "      <th>License</th>\n",
       "      <th>Authors.0</th>\n",
       "      <th>Authors.1</th>\n",
       "      <th>Authors.2</th>\n",
       "      <th>Authors.3</th>\n",
       "      <th>Authors.4</th>\n",
       "      <th>Authors.5</th>\n",
       "      <th>Authors.6</th>\n",
       "      <th>...</th>\n",
       "      <th>SliceTiming.90</th>\n",
       "      <th>SliceTiming.91</th>\n",
       "      <th>SliceTiming.92</th>\n",
       "      <th>SliceTiming.93</th>\n",
       "      <th>SliceTiming.94</th>\n",
       "      <th>SliceTiming.95</th>\n",
       "      <th>SliceTiming.96</th>\n",
       "      <th>SliceTiming.97</th>\n",
       "      <th>SliceTiming.98</th>\n",
       "      <th>SliceTiming.99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__file__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ds005264/dataset_description.json</th>\n",
       "      <td>SoCal Kinesia and Incentivization for Parkinso...</td>\n",
       "      <td>1.8.0</td>\n",
       "      <td>CC0</td>\n",
       "      <td>Neil M. Dundon</td>\n",
       "      <td>Elizabeth Rizor</td>\n",
       "      <td>Joanne Stasiak</td>\n",
       "      <td>Jingyi Wang</td>\n",
       "      <td>Kiana Sabugo</td>\n",
       "      <td>Christina Villaneuva</td>\n",
       "      <td>Parker Barandon</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/participants.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/sub-01/anat/sub-01_acq-1_T1w.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/sub-01/anat/sub-01_acq-2_T1w.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/sub-01/anat/sub-01_acq-3_T1w.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Name  \\\n",
       "__file__                                                                                        \n",
       "ds005264/dataset_description.json           SoCal Kinesia and Incentivization for Parkinso...   \n",
       "ds005264/participants.json                                                                NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json                                                NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json                                                NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json                                                NaN   \n",
       "\n",
       "                                           BIDSVersion License  \\\n",
       "__file__                                                         \n",
       "ds005264/dataset_description.json                1.8.0     CC0   \n",
       "ds005264/participants.json                         NaN     NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json         NaN     NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json         NaN     NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json         NaN     NaN   \n",
       "\n",
       "                                                 Authors.0        Authors.1  \\\n",
       "__file__                                                                      \n",
       "ds005264/dataset_description.json           Neil M. Dundon  Elizabeth Rizor   \n",
       "ds005264/participants.json                             NaN              NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json             NaN              NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json             NaN              NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json             NaN              NaN   \n",
       "\n",
       "                                                 Authors.2    Authors.3  \\\n",
       "__file__                                                                  \n",
       "ds005264/dataset_description.json           Joanne Stasiak  Jingyi Wang   \n",
       "ds005264/participants.json                             NaN          NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json             NaN          NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json             NaN          NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json             NaN          NaN   \n",
       "\n",
       "                                               Authors.4  \\\n",
       "__file__                                                   \n",
       "ds005264/dataset_description.json           Kiana Sabugo   \n",
       "ds005264/participants.json                           NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json           NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json           NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json           NaN   \n",
       "\n",
       "                                                       Authors.5  \\\n",
       "__file__                                                           \n",
       "ds005264/dataset_description.json           Christina Villaneuva   \n",
       "ds005264/participants.json                                   NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json                   NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json                   NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json                   NaN   \n",
       "\n",
       "                                                  Authors.6  ...  \\\n",
       "__file__                                                     ...   \n",
       "ds005264/dataset_description.json           Parker Barandon  ...   \n",
       "ds005264/participants.json                              NaN  ...   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json              NaN  ...   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json              NaN  ...   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json              NaN  ...   \n",
       "\n",
       "                                           SliceTiming.90 SliceTiming.91  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.92 SliceTiming.93  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.94 SliceTiming.95  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.96 SliceTiming.97  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.98 SliceTiming.99  \n",
       "__file__                                                                  \n",
       "ds005264/dataset_description.json                     NaN            NaN  \n",
       "ds005264/participants.json                            NaN            NaN  \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN  \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN  \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = jsons_to_dataframe(\"https://openneuro.org/datasets/ds005264\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'BIDSVersion',\n",
       " 'License',\n",
       " 'Authors.0',\n",
       " 'Authors.1',\n",
       " 'Authors.2',\n",
       " 'Authors.3',\n",
       " 'Authors.4',\n",
       " 'Authors.5',\n",
       " 'Authors.6',\n",
       " 'Authors.7',\n",
       " 'Authors.8',\n",
       " 'Authors.9',\n",
       " 'HowToAcknowledge',\n",
       " 'Funding.0',\n",
       " 'EthicsApprovals.0',\n",
       " 'EthicsApprovals.1',\n",
       " 'ReferencesAndLinks.0',\n",
       " 'ReferencesAndLinks.1',\n",
       " 'DatasetDOI',\n",
       " 'participant_id.Description',\n",
       " 'Age.Description',\n",
       " 'Age.Units',\n",
       " 'Age.Levels.n/a',\n",
       " 'Handed.Description',\n",
       " 'Handed.Levels.R',\n",
       " 'Handed.Levels.L',\n",
       " 'Gender.Description',\n",
       " 'Gender.Levels.M',\n",
       " 'Gender.Levels.F',\n",
       " 'Gender.Levels.NB',\n",
       " 'Group.Description',\n",
       " 'Group.Levels.control',\n",
       " 'Group.Levels.pd',\n",
       " 'Modality',\n",
       " 'MagneticFieldStrength',\n",
       " 'ImagingFrequency',\n",
       " 'Manufacturer',\n",
       " 'ManufacturersModelName',\n",
       " 'InstitutionName',\n",
       " 'DeviceSerialNumber',\n",
       " 'BodyPartExamined',\n",
       " 'PatientPosition',\n",
       " 'SoftwareVersions',\n",
       " 'MRAcquisitionType',\n",
       " 'SeriesDescription',\n",
       " 'ProtocolName',\n",
       " 'ScanningSequence',\n",
       " 'SequenceVariant',\n",
       " 'ScanOptions',\n",
       " 'SequenceName',\n",
       " 'ImageType.0',\n",
       " 'ImageType.1',\n",
       " 'ImageType.2',\n",
       " 'ImageType.3',\n",
       " 'SeriesNumber',\n",
       " 'AcquisitionTime',\n",
       " 'AcquisitionNumber',\n",
       " 'SliceThickness',\n",
       " 'SAR',\n",
       " 'EchoTime',\n",
       " 'RepetitionTime',\n",
       " 'InversionTime',\n",
       " 'FlipAngle',\n",
       " 'PartialFourier',\n",
       " 'BaseResolution',\n",
       " 'ShimSetting.0',\n",
       " 'ShimSetting.1',\n",
       " 'ShimSetting.2',\n",
       " 'ShimSetting.3',\n",
       " 'ShimSetting.4',\n",
       " 'ShimSetting.5',\n",
       " 'ShimSetting.6',\n",
       " 'ShimSetting.7',\n",
       " 'TxRefAmp',\n",
       " 'PhaseResolution',\n",
       " 'PhaseOversampling',\n",
       " 'ReceiveCoilName',\n",
       " 'PulseSequenceDetails',\n",
       " 'RefLinesPE',\n",
       " 'ConsistencyInfo',\n",
       " 'PercentPhaseFOV',\n",
       " 'PercentSampling',\n",
       " 'PhaseEncodingSteps',\n",
       " 'AcquisitionMatrixPE',\n",
       " 'ReconMatrixPE',\n",
       " 'ParallelReductionFactorInPlane',\n",
       " 'PixelBandwidth',\n",
       " 'DwellTime',\n",
       " 'ImageOrientationPatientDICOM.0',\n",
       " 'ImageOrientationPatientDICOM.1',\n",
       " 'ImageOrientationPatientDICOM.2',\n",
       " 'ImageOrientationPatientDICOM.3',\n",
       " 'ImageOrientationPatientDICOM.4',\n",
       " 'ImageOrientationPatientDICOM.5',\n",
       " 'InPlanePhaseEncodingDirectionDICOM',\n",
       " 'ConversionSoftware',\n",
       " 'ConversionSoftwareVersion',\n",
       " 'ImageType.4',\n",
       " 'RawImage',\n",
       " 'ImageType.5',\n",
       " 'SpacingBetweenSlices',\n",
       " 'WipMemBlock',\n",
       " 'MultibandAccelerationFactor',\n",
       " 'EchoTrainLength',\n",
       " 'BandwidthPerPixelPhaseEncode',\n",
       " 'EffectiveEchoSpacing',\n",
       " 'DerivedVendorReportedEchoSpacing',\n",
       " 'TotalReadoutTime',\n",
       " 'PhaseEncodingDirection',\n",
       " 'SliceTiming.0',\n",
       " 'SliceTiming.1',\n",
       " 'SliceTiming.2',\n",
       " 'SliceTiming.3',\n",
       " 'SliceTiming.4',\n",
       " 'SliceTiming.5',\n",
       " 'SliceTiming.6',\n",
       " 'SliceTiming.7',\n",
       " 'SliceTiming.8',\n",
       " 'SliceTiming.9',\n",
       " 'SliceTiming.10',\n",
       " 'SliceTiming.11',\n",
       " 'SliceTiming.12',\n",
       " 'SliceTiming.13',\n",
       " 'SliceTiming.14',\n",
       " 'SliceTiming.15',\n",
       " 'SliceTiming.16',\n",
       " 'SliceTiming.17',\n",
       " 'SliceTiming.18',\n",
       " 'SliceTiming.19',\n",
       " 'SliceTiming.20',\n",
       " 'SliceTiming.21',\n",
       " 'SliceTiming.22',\n",
       " 'SliceTiming.23',\n",
       " 'SliceTiming.24',\n",
       " 'SliceTiming.25',\n",
       " 'SliceTiming.26',\n",
       " 'SliceTiming.27',\n",
       " 'SliceTiming.28',\n",
       " 'SliceTiming.29',\n",
       " 'SliceTiming.30',\n",
       " 'SliceTiming.31',\n",
       " 'SliceTiming.32',\n",
       " 'SliceTiming.33',\n",
       " 'SliceTiming.34',\n",
       " 'SliceTiming.35',\n",
       " 'SliceTiming.36',\n",
       " 'SliceTiming.37',\n",
       " 'SliceTiming.38',\n",
       " 'SliceTiming.39',\n",
       " 'SliceTiming.40',\n",
       " 'SliceTiming.41',\n",
       " 'SliceTiming.42',\n",
       " 'SliceTiming.43',\n",
       " 'SliceTiming.44',\n",
       " 'SliceTiming.45',\n",
       " 'SliceTiming.46',\n",
       " 'SliceTiming.47',\n",
       " 'SliceTiming.48',\n",
       " 'SliceTiming.49',\n",
       " 'SliceTiming.50',\n",
       " 'SliceTiming.51',\n",
       " 'SliceTiming.52',\n",
       " 'SliceTiming.53',\n",
       " 'SliceTiming.54',\n",
       " 'SliceTiming.55',\n",
       " 'SliceTiming.56',\n",
       " 'SliceTiming.57',\n",
       " 'SliceTiming.58',\n",
       " 'SliceTiming.59',\n",
       " 'SliceTiming.60',\n",
       " 'SliceTiming.61',\n",
       " 'SliceTiming.62',\n",
       " 'SliceTiming.63',\n",
       " 'SliceTiming.64',\n",
       " 'SliceTiming.65',\n",
       " 'SliceTiming.66',\n",
       " 'SliceTiming.67',\n",
       " 'SliceTiming.68',\n",
       " 'SliceTiming.69',\n",
       " 'ImageType.6',\n",
       " 'EchoNumber',\n",
       " 'SliceTiming.70',\n",
       " 'SliceTiming.71',\n",
       " 'SliceTiming.72',\n",
       " 'SliceTiming.73',\n",
       " 'SliceTiming.74',\n",
       " 'SliceTiming.75',\n",
       " 'SliceTiming.76',\n",
       " 'SliceTiming.77',\n",
       " 'SliceTiming.78',\n",
       " 'SliceTiming.79',\n",
       " 'SliceTiming.80',\n",
       " 'SliceTiming.81',\n",
       " 'SliceTiming.82',\n",
       " 'SliceTiming.83',\n",
       " 'TaskName',\n",
       " 'Columns.0',\n",
       " 'SamplingFrequency',\n",
       " 'StartTime',\n",
       " 'InstitutionalDepartmentName',\n",
       " 'InstitutionAddress',\n",
       " 'StationName',\n",
       " 'ProcedureStepDescription',\n",
       " 'CoilString',\n",
       " 'ImageComments',\n",
       " 'SliceTiming.84',\n",
       " 'SliceTiming.85',\n",
       " 'SliceTiming.86',\n",
       " 'SliceTiming.87',\n",
       " 'SliceTiming.88',\n",
       " 'SliceTiming.89',\n",
       " 'SliceTiming.90',\n",
       " 'SliceTiming.91',\n",
       " 'SliceTiming.92',\n",
       " 'SliceTiming.93',\n",
       " 'SliceTiming.94',\n",
       " 'SliceTiming.95',\n",
       " 'SliceTiming.96',\n",
       " 'SliceTiming.97',\n",
       " 'SliceTiming.98',\n",
       " 'SliceTiming.99']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_from_TR()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "everything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
