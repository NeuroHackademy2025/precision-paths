{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was made with the help of AI tools, including ChatGPT and GitHub Copilot.\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import nibabel as nib\n",
    "import io\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the latest version of a given OpenNueo datsey\n",
    "def get_latest_snapshot(dataset_id: str):\n",
    "    \"\"\"\n",
    "    Fetch the latest snapshot tag for a given OpenNeuro dataset ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_id : str\n",
    "        The OpenNeuro dataset ID (e.g., \"ds000001\").\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The latest snapshot tag (version) for the dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    graphql_url = \"https://openneuro.org/crn/graphql\" # GraphQL endpoint for OpenNeuro\n",
    "    \n",
    "    # GraphQL query to fetch dataset snapshots\n",
    "    query = \"\"\"\n",
    "      query ($id: ID!) {\n",
    "        dataset(id: $id) {\n",
    "          snapshots {\n",
    "            tag\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    # Make the GraphQL request to fetch snapshots\n",
    "    res = requests.post(graphql_url, json={\"query\": query, \"variables\": {\"id\": dataset_id}})\n",
    "    res.raise_for_status() # Check for HTTP errors\n",
    "    snaps = res.json()[\"data\"][\"dataset\"][\"snapshots\"] # Extract snapshots\n",
    "    if not snaps: # Check if there are any snapshots\n",
    "        raise Exception(\"No snapshots found.\")\n",
    "    latest = sorted([s[\"tag\"] for s in snaps], reverse=True)[0] # Get the latest tag\n",
    "    return latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get the urls of all JSON files for a specific version of an OpenNeuro dataset\n",
    "# def get_json_urls(dataset_id: str, version_tag: str):\n",
    "#     \"\"\"\n",
    "#     Fetch URLs of JSON files for a specific version of an OpenNeuro dataset.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataset_id : str\n",
    "#         The OpenNeuro dataset ID (e.g., \"ds000001\").\n",
    "#     version_tag : str\n",
    "#         The version tag (snapshot) to fetch JSON files from.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dict\n",
    "#         A dictionary mapping JSON filenames to their download URLs.\n",
    "#     \"\"\"\n",
    "\n",
    "#     graphql_url = \"https://openneuro.org/crn/graphql\" # GraphQL endpoint for OpenNeuro\n",
    "\n",
    "#     # GraphQL query to fetch files for a specific snapshot\n",
    "#     query = \"\"\"\n",
    "#       query ($id: ID!, $tag: String!) {\n",
    "#         snapshot(datasetId: $id, tag: $tag) {\n",
    "#             files {\n",
    "#             filename\n",
    "#             urls\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Make the GraphQL request to fetch files for the specified snapshot\n",
    "#     res = requests.post(graphql_url, json={\"query\": query, \"variables\": {\"id\": dataset_id, \"tag\": version_tag}})\n",
    "#     if res.status_code != 200: # Check for HTTP errors\n",
    "#         print(\"Response content:\\n\", res.text)\n",
    "#         raise Exception(f\"GraphQL error fetching version {version_tag}: {res.status_code}\")\n",
    "#     files = res.json()[\"data\"][\"snapshot\"][\"files\"]\n",
    "    \n",
    "#     # Recursively collect all .json files\n",
    "#     def collect_json_files(directory, current_path=\"\"):\n",
    "#         jsons = {}\n",
    "#         for f in directory.get(\"files\", []):\n",
    "#             if f[\"filename\"].endswith(\".json\"):\n",
    "#                 full_path = f\"{current_path}{f['filename']}\"\n",
    "#                 jsons[full_path] = f[\"urls\"][0]\n",
    "#         for subdir in directory.get(\"directories\", []):\n",
    "#             sub_path = f\"{current_path}{subdir['name']}/\"\n",
    "#             jsons.update(collect_json_files(subdir, sub_path))\n",
    "#         return jsons\n",
    "    \n",
    "#     json_files = {f[\"filename\"]: f[\"urls\"][0] for f in files if f[\"filename\"].endswith(\".json\")}\n",
    "\n",
    "#     print(f\"Found {len(json_files)} JSON files.\")\n",
    "#     print(\"Examples:\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\" --\", example)\n",
    "\n",
    "#     return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_json_urls(dataset_id: str, version_tag: str):\n",
    "#     \"\"\"\n",
    "#     Fetch URLs of all JSON files for a specific version of an OpenNeuro dataset.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataset_id : str\n",
    "#         The OpenNeuro dataset ID (e.g., \"ds000001\").\n",
    "#     version_tag : str\n",
    "#         The version tag (snapshot) to fetch JSON files from.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dict\n",
    "#         A dictionary mapping JSON file paths (with folders) to their download URLs.\n",
    "#     \"\"\"\n",
    "\n",
    "#     graphql_url = \"https://openneuro.org/crn/graphql\"\n",
    "\n",
    "#     query = \"\"\"\n",
    "#     query ($id: ID!, $tag: String!) {\n",
    "#       snapshot(datasetId: $id, tag: $tag) {\n",
    "#         files {\n",
    "#           filename\n",
    "#           urls\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "#     \"\"\"\n",
    "\n",
    "#     res = requests.post(graphql_url, json={\"query\": query, \"variables\": {\"id\": dataset_id, \"tag\": version_tag}})\n",
    "#     if res.status_code != 200:\n",
    "#         print(\"Response content:\\n\", res.text)\n",
    "#         raise Exception(f\"GraphQL error fetching version {version_tag}: {res.status_code}\")\n",
    "\n",
    "#     files = res.json()[\"data\"][\"snapshot\"][\"files\"]\n",
    "\n",
    "#     # Filter for JSON files and map full path -> first url\n",
    "#     json_files = {f[\"filename\"]: f[\"urls\"][0] for f in files if f[\"filename\"].endswith(\".json\")}\n",
    "\n",
    "#     print(f\"✅ Found {len(json_files)} JSON files.\")\n",
    "#     print(\"Examples:\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\"  -\", example)\n",
    "\n",
    "#     return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# def get_json_urls(dataset_id: str, version_tag: str):\n",
    "#     \"\"\"\n",
    "#     Fetch all JSON files (including nested) for a given dataset and version using the OpenNeuro REST API manifest.\n",
    "\n",
    "#     Returns dict mapping full path -> URL\n",
    "#     \"\"\"\n",
    "#     manifest_url = f\"https://openneuro.org/crn/datasets/{dataset_id}/snapshots/{version_tag}/contents\"\n",
    "\n",
    "#     res = requests.get(manifest_url)\n",
    "#     res.raise_for_status()\n",
    "\n",
    "#     contents = res.json()  # This is a list of file/directory dicts recursively\n",
    "\n",
    "#     json_files = {}\n",
    "\n",
    "#     def recurse_files(entries, prefix=\"\"):\n",
    "#         for entry in entries:\n",
    "#             if entry[\"type\"] == \"file\" and entry[\"name\"].endswith(\".json\"):\n",
    "#                 path = prefix + entry[\"name\"]\n",
    "#                 # The URL is in 's3Uri' or 'url' or build from key? Let's check:\n",
    "#                 # Try 'url' field if present, else construct from s3Uri\n",
    "#                 url = entry.get(\"url\")\n",
    "#                 if not url:\n",
    "#                     url = f\"https://s3.amazonaws.com/openneuro.org/{dataset_id}/{path}\"\n",
    "#                 json_files[path] = url\n",
    "#             elif entry[\"type\"] == \"directory\":\n",
    "#                 recurse_files(entry[\"contents\"], prefix + entry[\"name\"] + \"/\")\n",
    "\n",
    "#     recurse_files(contents)\n",
    "\n",
    "#     print(f\"✅ Found {len(json_files)} JSON files.\")\n",
    "#     print(\"Examples:\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\" -\", example)\n",
    "\n",
    "#     return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# def list_s3_json_files(dataset_id):\n",
    "#     s3 = boto3.client('s3')\n",
    "#     bucket = 'openneuro.org'\n",
    "#     prefix = f\"{dataset_id}/\"\n",
    "\n",
    "#     paginator = s3.get_paginator('list_objects_v2')\n",
    "#     pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "#     json_files = {}\n",
    "\n",
    "#     for page in pages:\n",
    "#         for obj in page.get('Contents', []):\n",
    "#             key = obj['Key']\n",
    "#             if key.endswith('.json'):\n",
    "#                 url = f\"https://s3.amazonaws.com/{bucket}/{key}\"\n",
    "#                 json_files[key] = url\n",
    "\n",
    "#     print(f\"Found {len(json_files)} JSON files.\")\n",
    "#     for example in list(json_files.keys())[:5]:\n",
    "#         print(\" -\", example)\n",
    "\n",
    "#     return json_files\n",
    "\n",
    "# json_urls = list_s3_json_files('ds005264')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_json_files(dataset_id):\n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    bucket = 'openneuro.org'\n",
    "    prefix = f\"{dataset_id}/\"\n",
    "\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "    json_files = {}\n",
    "\n",
    "    for page in pages:\n",
    "        for obj in page.get('Contents', []):\n",
    "            key = obj['Key']\n",
    "            if key.endswith('.json'):\n",
    "                url = f\"https://s3.amazonaws.com/{bucket}/{key}\"\n",
    "                json_files[key] = url\n",
    "\n",
    "    print(f\"Found {len(json_files)} JSON files.\")\n",
    "    for example in list(json_files.keys())[:10]:\n",
    "        print(\" -\", example)\n",
    "\n",
    "    return json_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# flatten json objects into a single-level dictionary\n",
    "def flatten_json(y):\n",
    "    \"\"\"\n",
    "    Flatten a nested JSON object into a single-level dictionary with dot notation keys.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : dict\n",
    "        The nested JSON object to flatten.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A flattened dictionary with keys in dot notation.\n",
    "    \"\"\"\n",
    "\n",
    "    out = {} # Initialize output dictionary\n",
    "\n",
    "    # Recursive function to flatten the JSON\n",
    "    def _flatten(x, name=\"\"):\n",
    "        if isinstance(x, dict):\n",
    "            for k,v in x.items():\n",
    "                _flatten(v, name + k + \".\")\n",
    "        elif isinstance(x, list):\n",
    "            for i,v in enumerate(x):\n",
    "                _flatten(v, name + str(i) + \".\")\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "    _flatten(y)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load JSON files from an OpenNeuro dataset URL into a Pandas DataFrame\n",
    "# def jsons_to_dataframe(openneuro_url: str):\n",
    "#     \"\"\"\n",
    "#     Load JSON files from an OpenNeuro dataset URL into a Pandas DataFrame.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     openneuro_url : str\n",
    "#         The OpenNeuro dataset URL (e.g., \"https://openneuro.org/datasets/ds000001/versions/1.0.0\").\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         A Pandas DataFrame containing the flattened JSON data, indexed by file name.\n",
    "#     \"\"\"\n",
    "\n",
    "#     parsed = urlparse(openneuro_url)\n",
    "#     parts = parsed.path.strip(\"/\").split(\"/\")\n",
    "#     dataset_id = parts[1]\n",
    "#     version = parts[3] if len(parts) > 3 and parts[2] == \"versions\" else None\n",
    "\n",
    "#     if version is None:\n",
    "#         version = get_latest_snapshot(dataset_id) #######\n",
    "#         print(f\"No version specified — using latest: {version}\")\n",
    "#     else:\n",
    "#         print(f\"Using specified version: {version}\")\n",
    "\n",
    "#     json_urls = get_json_urls(dataset_id, version) #######\n",
    "#     print(f\"Found {len(json_urls)} JSON files for version {version}\")\n",
    "\n",
    "#     records = []\n",
    "#     for fname, url in tqdm(json_urls.items(), desc=\"Downloading JSONs\"):\n",
    "#         r = requests.get(url)\n",
    "#         r.raise_for_status()\n",
    "#         flat = flatten_json(r.json()) #######\n",
    "#         flat[\"__file__\"] = fname\n",
    "#         records.append(flat)\n",
    "\n",
    "#     df = pd.DataFrame(records).set_index(\"__file__\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsons_to_dataframe(openneuro_url: str):\n",
    "    \"\"\"\n",
    "    Load JSON files from an OpenNeuro dataset URL into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    openneuro_url : str\n",
    "        The OpenNeuro dataset URL (e.g., \"https://openneuro.org/datasets/ds000001/versions/1.0.0\").\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A Pandas DataFrame containing the flattened JSON data, indexed by file name.\n",
    "    \"\"\"\n",
    "\n",
    "    parsed = urlparse(openneuro_url)\n",
    "    parts = parsed.path.strip(\"/\").split(\"/\")\n",
    "    dataset_id = parts[1]\n",
    "    # version is not used for S3 listing, so no need to parse it here\n",
    "\n",
    "    print(f\"Listing JSON files for dataset: {dataset_id} from S3 (no versioning)\")\n",
    "\n",
    "    # Call your S3 JSON file lister WITHOUT version arg\n",
    "    json_urls = list_s3_json_files(dataset_id)  # <-- Removed version argument here\n",
    "\n",
    "    print(f\"Found {len(json_urls)} JSON files.\")\n",
    "\n",
    "    records = []\n",
    "    for fname, url in tqdm(json_urls.items(), desc=\"Downloading JSONs\"):\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        flat = flatten_json(r.json())\n",
    "        flat[\"__file__\"] = fname\n",
    "        records.append(flat)\n",
    "\n",
    "    df = pd.DataFrame(records).set_index(\"__file__\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_json_urls(\"ds005264\", \"1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 296 JSON files.\n",
      " - ds005264/dataset_description.json\n",
      " - ds005264/participants.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-1_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-2_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-3_T1w.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-AP_epi.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-PA_epi.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_bold.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_sbref.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-2_bold.json\n"
     ]
    }
   ],
   "source": [
    "# # Example usage\n",
    "# json_urls = list_s3_json_files('ds005264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing JSON files for dataset: ds005264 from S3 (no versioning)\n",
      "Found 296 JSON files.\n",
      " - ds005264/dataset_description.json\n",
      " - ds005264/participants.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-1_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-2_T1w.json\n",
      " - ds005264/sub-01/anat/sub-01_acq-3_T1w.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-AP_epi.json\n",
      " - ds005264/sub-01/fmap/sub-01_dir-PA_epi.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_bold.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-1_sbref.json\n",
      " - ds005264/sub-01/func/sub-01_task-rest_echo-2_bold.json\n",
      "Found 296 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading JSONs: 100%|██████████| 296/296 [01:15<00:00,  3.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>BIDSVersion</th>\n",
       "      <th>License</th>\n",
       "      <th>Authors.0</th>\n",
       "      <th>Authors.1</th>\n",
       "      <th>Authors.2</th>\n",
       "      <th>Authors.3</th>\n",
       "      <th>Authors.4</th>\n",
       "      <th>Authors.5</th>\n",
       "      <th>Authors.6</th>\n",
       "      <th>...</th>\n",
       "      <th>SliceTiming.90</th>\n",
       "      <th>SliceTiming.91</th>\n",
       "      <th>SliceTiming.92</th>\n",
       "      <th>SliceTiming.93</th>\n",
       "      <th>SliceTiming.94</th>\n",
       "      <th>SliceTiming.95</th>\n",
       "      <th>SliceTiming.96</th>\n",
       "      <th>SliceTiming.97</th>\n",
       "      <th>SliceTiming.98</th>\n",
       "      <th>SliceTiming.99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__file__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ds005264/dataset_description.json</th>\n",
       "      <td>SoCal Kinesia and Incentivization for Parkinso...</td>\n",
       "      <td>1.8.0</td>\n",
       "      <td>CC0</td>\n",
       "      <td>Neil M. Dundon</td>\n",
       "      <td>Elizabeth Rizor</td>\n",
       "      <td>Joanne Stasiak</td>\n",
       "      <td>Jingyi Wang</td>\n",
       "      <td>Kiana Sabugo</td>\n",
       "      <td>Christina Villaneuva</td>\n",
       "      <td>Parker Barandon</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/participants.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/sub-01/anat/sub-01_acq-1_T1w.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/sub-01/anat/sub-01_acq-2_T1w.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005264/sub-01/anat/sub-01_acq-3_T1w.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Name  \\\n",
       "__file__                                                                                        \n",
       "ds005264/dataset_description.json           SoCal Kinesia and Incentivization for Parkinso...   \n",
       "ds005264/participants.json                                                                NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json                                                NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json                                                NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json                                                NaN   \n",
       "\n",
       "                                           BIDSVersion License  \\\n",
       "__file__                                                         \n",
       "ds005264/dataset_description.json                1.8.0     CC0   \n",
       "ds005264/participants.json                         NaN     NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json         NaN     NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json         NaN     NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json         NaN     NaN   \n",
       "\n",
       "                                                 Authors.0        Authors.1  \\\n",
       "__file__                                                                      \n",
       "ds005264/dataset_description.json           Neil M. Dundon  Elizabeth Rizor   \n",
       "ds005264/participants.json                             NaN              NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json             NaN              NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json             NaN              NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json             NaN              NaN   \n",
       "\n",
       "                                                 Authors.2    Authors.3  \\\n",
       "__file__                                                                  \n",
       "ds005264/dataset_description.json           Joanne Stasiak  Jingyi Wang   \n",
       "ds005264/participants.json                             NaN          NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json             NaN          NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json             NaN          NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json             NaN          NaN   \n",
       "\n",
       "                                               Authors.4  \\\n",
       "__file__                                                   \n",
       "ds005264/dataset_description.json           Kiana Sabugo   \n",
       "ds005264/participants.json                           NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json           NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json           NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json           NaN   \n",
       "\n",
       "                                                       Authors.5  \\\n",
       "__file__                                                           \n",
       "ds005264/dataset_description.json           Christina Villaneuva   \n",
       "ds005264/participants.json                                   NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json                   NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json                   NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json                   NaN   \n",
       "\n",
       "                                                  Authors.6  ...  \\\n",
       "__file__                                                     ...   \n",
       "ds005264/dataset_description.json           Parker Barandon  ...   \n",
       "ds005264/participants.json                              NaN  ...   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json              NaN  ...   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json              NaN  ...   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json              NaN  ...   \n",
       "\n",
       "                                           SliceTiming.90 SliceTiming.91  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.92 SliceTiming.93  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.94 SliceTiming.95  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.96 SliceTiming.97  \\\n",
       "__file__                                                                   \n",
       "ds005264/dataset_description.json                     NaN            NaN   \n",
       "ds005264/participants.json                            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN   \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN   \n",
       "\n",
       "                                           SliceTiming.98 SliceTiming.99  \n",
       "__file__                                                                  \n",
       "ds005264/dataset_description.json                     NaN            NaN  \n",
       "ds005264/participants.json                            NaN            NaN  \n",
       "ds005264/sub-01/anat/sub-01_acq-1_T1w.json            NaN            NaN  \n",
       "ds005264/sub-01/anat/sub-01_acq-2_T1w.json            NaN            NaN  \n",
       "ds005264/sub-01/anat/sub-01_acq-3_T1w.json            NaN            NaN  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = jsons_to_dataframe(\"https://openneuro.org/datasets/ds005264\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def get_scan_duration(df):\n",
    "#     \"\"\"\n",
    "#     Calculate the duration of each scan in seconds from combinations of the 'AcquisitionDuration','SeriesTime','AcquisitionTime', and 'RepetitionTime' fields in the DataFrame.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     df : pd.DataFrame\n",
    "#         The DataFrame containing flattened JSON data with a 'duration' field.\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.Series\n",
    "#         A Pandas Series containing the scan durations in seconds.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # check if dataframe has any of the required columns\n",
    "#     required_columns = ['AcquisitionDuration', 'SeriesTime', 'AcquisitionTime', 'RepetitionTime', 'NumberOfVolumes']\n",
    "#     if not any(col in df.columns for col in required_columns):\n",
    "#         raise ValueError(f\"DataFrame lacks all required columns: {required_columns}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing JSON files for dataset: ds005118 from S3 (no versioning)\n",
      "Found 240 JSON files.\n",
      " - ds005118/dataset_description.json\n",
      " - ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-func01_dir-AP_run-01_epi.json\n",
      " - ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-func01_dir-PA_run-01_epi.json\n",
      " - ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-01_bold.json\n",
      " - ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-02_bold.json\n",
      " - ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-03_bold.json\n",
      " - ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-04_bold.json\n",
      " - ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-05_bold.json\n",
      " - ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-02_echo-01_bold.json\n",
      " - ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-02_echo-02_bold.json\n",
      "Found 240 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading JSONs: 100%|██████████| 240/240 [01:04<00:00,  3.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>BIDSVersion</th>\n",
       "      <th>License</th>\n",
       "      <th>Authors.0</th>\n",
       "      <th>Authors.1</th>\n",
       "      <th>HowToAcknowledge</th>\n",
       "      <th>Funding.0</th>\n",
       "      <th>ReferencesAndLinks.0</th>\n",
       "      <th>DatasetDOI</th>\n",
       "      <th>Modality</th>\n",
       "      <th>...</th>\n",
       "      <th>SliceTiming.66</th>\n",
       "      <th>SliceTiming.67</th>\n",
       "      <th>SliceTiming.68</th>\n",
       "      <th>SliceTiming.69</th>\n",
       "      <th>SliceTiming.70</th>\n",
       "      <th>SliceTiming.71</th>\n",
       "      <th>EchoNumber</th>\n",
       "      <th>TaskName</th>\n",
       "      <th>CogAtlasID</th>\n",
       "      <th>Instructions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__file__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ds005118/dataset_description.json</th>\n",
       "      <td>Weill Cornell Medicine Multi-echo (WCM-ME) Dat...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>CC0</td>\n",
       "      <td>Charles J. Lynch</td>\n",
       "      <td>Conor Liston</td>\n",
       "      <td>When using this data, please cite Lynch et al....</td>\n",
       "      <td></td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/33357444/</td>\n",
       "      <td>doi:10.18112/openneuro.ds005118.v1.0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-func01_dir-AP_run-01_epi.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-func01_dir-PA_run-01_epi.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-01_bold.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6675</td>\n",
       "      <td>1.2225</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-02_bold.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6675</td>\n",
       "      <td>1.2225</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 Name  \\\n",
       "__file__                                                                                                \n",
       "ds005118/dataset_description.json                   Weill Cornell Medicine Multi-echo (WCM-ME) Dat...   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                                NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                                NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                                NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                                NaN   \n",
       "\n",
       "                                                   BIDSVersion License  \\\n",
       "__file__                                                                 \n",
       "ds005118/dataset_description.json                        1.0.0     CC0   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...         NaN     NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...         NaN     NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         NaN     NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         NaN     NaN   \n",
       "\n",
       "                                                           Authors.0  \\\n",
       "__file__                                                               \n",
       "ds005118/dataset_description.json                   Charles J. Lynch   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...               NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...               NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...               NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...               NaN   \n",
       "\n",
       "                                                       Authors.1  \\\n",
       "__file__                                                           \n",
       "ds005118/dataset_description.json                   Conor Liston   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...           NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...           NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...           NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...           NaN   \n",
       "\n",
       "                                                                                     HowToAcknowledge  \\\n",
       "__file__                                                                                                \n",
       "ds005118/dataset_description.json                   When using this data, please cite Lynch et al....   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                                NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                                NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                                NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                                NaN   \n",
       "\n",
       "                                                   Funding.0  \\\n",
       "__file__                                                       \n",
       "ds005118/dataset_description.json                              \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...       NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...       NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...       NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...       NaN   \n",
       "\n",
       "                                                                         ReferencesAndLinks.0  \\\n",
       "__file__                                                                                        \n",
       "ds005118/dataset_description.json                   https://pubmed.ncbi.nlm.nih.gov/33357444/   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                        NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                        NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                        NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                        NaN   \n",
       "\n",
       "                                                                                DatasetDOI  \\\n",
       "__file__                                                                                     \n",
       "ds005118/dataset_description.json                   doi:10.18112/openneuro.ds005118.v1.0.0   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                     NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...                                     NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                     NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...                                     NaN   \n",
       "\n",
       "                                                   Modality  ...  \\\n",
       "__file__                                                     ...   \n",
       "ds005118/dataset_description.json                       NaN  ...   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...       MR  ...   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...       MR  ...   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...       MR  ...   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...       MR  ...   \n",
       "\n",
       "                                                    SliceTiming.66  \\\n",
       "__file__                                                             \n",
       "ds005118/dataset_description.json                              NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...             NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...             NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...          0.6675   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...          0.6675   \n",
       "\n",
       "                                                   SliceTiming.67  \\\n",
       "__file__                                                            \n",
       "ds005118/dataset_description.json                             NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         1.2225   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         1.2225   \n",
       "\n",
       "                                                   SliceTiming.68  \\\n",
       "__file__                                                            \n",
       "ds005118/dataset_description.json                             NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...          0.445   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...          0.445   \n",
       "\n",
       "                                                   SliceTiming.69  \\\n",
       "__file__                                                            \n",
       "ds005118/dataset_description.json                             NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...            1.0   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...            1.0   \n",
       "\n",
       "                                                   SliceTiming.70  \\\n",
       "__file__                                                            \n",
       "ds005118/dataset_description.json                             NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         0.2225   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         0.2225   \n",
       "\n",
       "                                                   SliceTiming.71 EchoNumber  \\\n",
       "__file__                                                                       \n",
       "ds005118/dataset_description.json                             NaN        NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN        NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...            NaN        NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         0.7775        NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...         0.7775        2.0   \n",
       "\n",
       "                                                   TaskName CogAtlasID  \\\n",
       "__file__                                                                 \n",
       "ds005118/dataset_description.json                       NaN        NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...      NaN        NaN   \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...      NaN        NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...      NaN        NaN   \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...      NaN        NaN   \n",
       "\n",
       "                                                   Instructions  \n",
       "__file__                                                         \n",
       "ds005118/dataset_description.json                           NaN  \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...          NaN  \n",
       "ds005118/sub-ME01/ses-func01/fmap/sub-ME01_ses-...          NaN  \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...          NaN  \n",
       "ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-...          NaN  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = jsons_to_dataframe(\"https://openneuro.org/datasets/ds005118\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'BIDSVersion',\n",
       " 'License',\n",
       " 'Authors.0',\n",
       " 'Authors.1',\n",
       " 'HowToAcknowledge',\n",
       " 'Funding.0',\n",
       " 'ReferencesAndLinks.0',\n",
       " 'DatasetDOI',\n",
       " 'Modality',\n",
       " 'MagneticFieldStrength',\n",
       " 'Manufacturer',\n",
       " 'ManufacturersModelName',\n",
       " 'InstitutionName',\n",
       " 'InstitutionalDepartmentName',\n",
       " 'InstitutionAddress',\n",
       " 'DeviceSerialNumber',\n",
       " 'StationName',\n",
       " 'BodyPartExamined',\n",
       " 'PatientPosition',\n",
       " 'ProcedureStepDescription',\n",
       " 'SoftwareVersions',\n",
       " 'MRAcquisitionType',\n",
       " 'SeriesDescription',\n",
       " 'ProtocolName',\n",
       " 'ScanningSequence',\n",
       " 'SequenceVariant',\n",
       " 'ScanOptions',\n",
       " 'SequenceName',\n",
       " 'ImageType.0',\n",
       " 'ImageType.1',\n",
       " 'ImageType.2',\n",
       " 'ImageType.3',\n",
       " 'SeriesNumber',\n",
       " 'AcquisitionTime',\n",
       " 'AcquisitionNumber',\n",
       " 'SliceThickness',\n",
       " 'SpacingBetweenSlices',\n",
       " 'SAR',\n",
       " 'EchoTime',\n",
       " 'RepetitionTime',\n",
       " 'FlipAngle',\n",
       " 'PartialFourier',\n",
       " 'BaseResolution',\n",
       " 'ShimSetting.0',\n",
       " 'ShimSetting.1',\n",
       " 'ShimSetting.2',\n",
       " 'ShimSetting.3',\n",
       " 'ShimSetting.4',\n",
       " 'ShimSetting.5',\n",
       " 'ShimSetting.6',\n",
       " 'ShimSetting.7',\n",
       " 'TxRefAmp',\n",
       " 'PhaseResolution',\n",
       " 'VendorReportedEchoSpacing',\n",
       " 'ReceiveCoilName',\n",
       " 'ReceiveCoilActiveElements',\n",
       " 'PulseSequenceDetails',\n",
       " 'ConsistencyInfo',\n",
       " 'PercentPhaseFOV',\n",
       " 'EchoTrainLength',\n",
       " 'PhaseEncodingSteps',\n",
       " 'AcquisitionMatrixPE',\n",
       " 'ReconMatrixPE',\n",
       " 'BandwidthPerPixelPhaseEncode',\n",
       " 'ParallelReductionFactorInPlane',\n",
       " 'EffectiveEchoSpacing',\n",
       " 'DerivedVendorReportedEchoSpacing',\n",
       " 'TotalReadoutTime',\n",
       " 'PixelBandwidth',\n",
       " 'DwellTime',\n",
       " 'PhaseEncodingDirection',\n",
       " 'ImageOrientationPatientDICOM.0',\n",
       " 'ImageOrientationPatientDICOM.1',\n",
       " 'ImageOrientationPatientDICOM.2',\n",
       " 'ImageOrientationPatientDICOM.3',\n",
       " 'ImageOrientationPatientDICOM.4',\n",
       " 'ImageOrientationPatientDICOM.5',\n",
       " 'InPlanePhaseEncodingDirectionDICOM',\n",
       " 'ConversionSoftware',\n",
       " 'ConversionSoftwareVersion',\n",
       " 'ImageType.4',\n",
       " 'ImageType.5',\n",
       " 'ImageType.6',\n",
       " 'ImageComments',\n",
       " 'MultibandAccelerationFactor',\n",
       " 'SliceTiming.0',\n",
       " 'SliceTiming.1',\n",
       " 'SliceTiming.2',\n",
       " 'SliceTiming.3',\n",
       " 'SliceTiming.4',\n",
       " 'SliceTiming.5',\n",
       " 'SliceTiming.6',\n",
       " 'SliceTiming.7',\n",
       " 'SliceTiming.8',\n",
       " 'SliceTiming.9',\n",
       " 'SliceTiming.10',\n",
       " 'SliceTiming.11',\n",
       " 'SliceTiming.12',\n",
       " 'SliceTiming.13',\n",
       " 'SliceTiming.14',\n",
       " 'SliceTiming.15',\n",
       " 'SliceTiming.16',\n",
       " 'SliceTiming.17',\n",
       " 'SliceTiming.18',\n",
       " 'SliceTiming.19',\n",
       " 'SliceTiming.20',\n",
       " 'SliceTiming.21',\n",
       " 'SliceTiming.22',\n",
       " 'SliceTiming.23',\n",
       " 'SliceTiming.24',\n",
       " 'SliceTiming.25',\n",
       " 'SliceTiming.26',\n",
       " 'SliceTiming.27',\n",
       " 'SliceTiming.28',\n",
       " 'SliceTiming.29',\n",
       " 'SliceTiming.30',\n",
       " 'SliceTiming.31',\n",
       " 'SliceTiming.32',\n",
       " 'SliceTiming.33',\n",
       " 'SliceTiming.34',\n",
       " 'SliceTiming.35',\n",
       " 'SliceTiming.36',\n",
       " 'SliceTiming.37',\n",
       " 'SliceTiming.38',\n",
       " 'SliceTiming.39',\n",
       " 'SliceTiming.40',\n",
       " 'SliceTiming.41',\n",
       " 'SliceTiming.42',\n",
       " 'SliceTiming.43',\n",
       " 'SliceTiming.44',\n",
       " 'SliceTiming.45',\n",
       " 'SliceTiming.46',\n",
       " 'SliceTiming.47',\n",
       " 'SliceTiming.48',\n",
       " 'SliceTiming.49',\n",
       " 'SliceTiming.50',\n",
       " 'SliceTiming.51',\n",
       " 'SliceTiming.52',\n",
       " 'SliceTiming.53',\n",
       " 'SliceTiming.54',\n",
       " 'SliceTiming.55',\n",
       " 'SliceTiming.56',\n",
       " 'SliceTiming.57',\n",
       " 'SliceTiming.58',\n",
       " 'SliceTiming.59',\n",
       " 'SliceTiming.60',\n",
       " 'SliceTiming.61',\n",
       " 'SliceTiming.62',\n",
       " 'SliceTiming.63',\n",
       " 'SliceTiming.64',\n",
       " 'SliceTiming.65',\n",
       " 'SliceTiming.66',\n",
       " 'SliceTiming.67',\n",
       " 'SliceTiming.68',\n",
       " 'SliceTiming.69',\n",
       " 'SliceTiming.70',\n",
       " 'SliceTiming.71',\n",
       " 'EchoNumber',\n",
       " 'TaskName',\n",
       " 'CogAtlasID',\n",
       " 'Instructions']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'AcquisitionDuration', 'SeriesTime', 'AcquisitionTime', 'RepetitionTime', 'NumberOfVolumes'\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>BIDSVersion</th>\n",
       "      <th>License</th>\n",
       "      <th>Authors.0</th>\n",
       "      <th>Authors.1</th>\n",
       "      <th>HowToAcknowledge</th>\n",
       "      <th>Funding.0</th>\n",
       "      <th>ReferencesAndLinks.0</th>\n",
       "      <th>DatasetDOI</th>\n",
       "      <th>Modality</th>\n",
       "      <th>...</th>\n",
       "      <th>SliceTiming.66</th>\n",
       "      <th>SliceTiming.67</th>\n",
       "      <th>SliceTiming.68</th>\n",
       "      <th>SliceTiming.69</th>\n",
       "      <th>SliceTiming.70</th>\n",
       "      <th>SliceTiming.71</th>\n",
       "      <th>EchoNumber</th>\n",
       "      <th>TaskName</th>\n",
       "      <th>CogAtlasID</th>\n",
       "      <th>Instructions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__file__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ds005118/task-rest_bold.json</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6675</td>\n",
       "      <td>1.2225</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rest</td>\n",
       "      <td>http://www.cognitiveatlas.org/term/id/trm_4c8a...</td>\n",
       "      <td>All you need to do is simply relax and look at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name BIDSVersion License Authors.0 Authors.1  \\\n",
       "__file__                                                                    \n",
       "ds005118/task-rest_bold.json  NaN         NaN     NaN       NaN       NaN   \n",
       "\n",
       "                             HowToAcknowledge Funding.0 ReferencesAndLinks.0  \\\n",
       "__file__                                                                       \n",
       "ds005118/task-rest_bold.json              NaN       NaN                  NaN   \n",
       "\n",
       "                             DatasetDOI Modality  ...  SliceTiming.66  \\\n",
       "__file__                                          ...                   \n",
       "ds005118/task-rest_bold.json        NaN       MR  ...          0.6675   \n",
       "\n",
       "                             SliceTiming.67 SliceTiming.68 SliceTiming.69  \\\n",
       "__file__                                                                    \n",
       "ds005118/task-rest_bold.json         1.2225          0.445            1.0   \n",
       "\n",
       "                             SliceTiming.70 SliceTiming.71 EchoNumber  \\\n",
       "__file__                                                                \n",
       "ds005118/task-rest_bold.json         0.2225         0.7775        NaN   \n",
       "\n",
       "                             TaskName  \\\n",
       "__file__                                \n",
       "ds005118/task-rest_bold.json     rest   \n",
       "\n",
       "                                                                     CogAtlasID  \\\n",
       "__file__                                                                          \n",
       "ds005118/task-rest_bold.json  http://www.cognitiveatlas.org/term/id/trm_4c8a...   \n",
       "\n",
       "                                                                   Instructions  \n",
       "__file__                                                                         \n",
       "ds005118/task-rest_bold.json  All you need to do is simply relax and look at...  \n",
       "\n",
       "[1 rows x 162 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_niigz_files(dataset_id):\n",
    "    \"\"\"\n",
    "    List all .nii.gz files in a given OpenNeuro dataset (via public S3).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_id : str\n",
    "        The OpenNeuro dataset ID (e.g., \"ds000001\").\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping file paths to their download URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    bucket = 'openneuro.org'\n",
    "    prefix = f\"{dataset_id}/\"\n",
    "\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "    niigz_files = {}\n",
    "\n",
    "    for page in pages:\n",
    "        for obj in page.get('Contents', []):\n",
    "            key = obj['Key']\n",
    "            if key.endswith('.nii.gz'):\n",
    "                url = f\"https://s3.amazonaws.com/{bucket}/{key}\"\n",
    "                niigz_files[key] = url\n",
    "\n",
    "    print(f\"Found {len(niigz_files)} NIfTI files (.nii.gz).\")\n",
    "    for example in list(niigz_files.keys())[:10]:\n",
    "        print(\" -\", example)\n",
    "\n",
    "    return niigz_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nii_files = list_s3_niigz_files(\"ds003814\")\n",
    "# nii_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nii_shape_from_url(url):\n",
    "    \"\"\"\n",
    "    Fetch a NIfTI file from a URL, decompress it if gzipped, and return its shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The s3 URL of the NIfTI file (can be gzipped).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        The shape of the NIfTI image (dimensions).\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Decompress gzip content\n",
    "    with gzip.GzipFile(fileobj=io.BytesIO(response.content)) as gz:\n",
    "        decompressed = gz.read()\n",
    "\n",
    "    # Use FileHolder with decompressed bytes for header and image\n",
    "    file_holder = nib.FileHolder(fileobj=io.BytesIO(decompressed))\n",
    "    img = nib.Nifti1Image.from_file_map({'header': file_holder, 'image': file_holder})\n",
    "\n",
    "    return img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (90, 90, 72, 640)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://s3.amazonaws.com/openneuro.org/ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-01_bold.nii.gz\"\n",
    "shape = get_nii_shape_from_url(url)\n",
    "print(\"Shape:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds005118/sub-ME01/ses-func01/func/sub-ME01_ses-func01_task-rest_run-01_echo-01_bold.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_time_from_TR(json_path: str, TR: float = None):\n",
    "    \"\"\"\n",
    "    Calculate the total scan time in seconds based on TR and number of volumes from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_path : str\n",
    "        The path to the JSON file containing scan metadata.\n",
    "    TR : float\n",
    "        The repetition time (TR) in seconds.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The total scan time in seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if TR is None:\n",
    "        with open(json_path, 'r') as f:\n",
    "            metadata = flatten_json(pd.read_json(f).to_dict(orient='records')[0])\n",
    "            TR = metadata.get('RepetitionTime', None)\n",
    "            if TR is None:\n",
    "                raise ValueError(\"JSON file does not contain 'RepetitionTime' field.\")\n",
    "\n",
    "    num_volumes = metadata.get('NumberOfVolumes', None)\n",
    "    if num_volumes is None:\n",
    "        shape = get_nii_shape_from_url(url)\n",
    "        if len(shape) < 4:\n",
    "            raise ValueError(\"NIfTI file does not have a time dimension (4th dimension).\")\n",
    "        num_volumes = shape[3]\n",
    "\n",
    "    return num_volumes * TR\n",
    "\n",
    "def convert_hhmmss_string(time_str: str):\n",
    "    \"\"\"\n",
    "    Convert a time string in HH:MM:SS format to seconds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_str : str\n",
    "        The time string in HH:MM:SS format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float   \n",
    "        The time in seconds.\n",
    "    \"\"\"\n",
    "    if not isinstance(time_str, str):\n",
    "        raise ValueError(\"Time string must be a string in HH:MM:SS format.\")\n",
    "    \n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(\"Time string must be in HH:MM:SS format.\")\n",
    "\n",
    "    hours, minutes, seconds = map(float, parts)\n",
    "    return hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "def get_scan_time_from_AcquisitionTime_SeriesTime(json_path: str, AcquisitionTime: str = None, SeriesTime: str = None):\n",
    "    \"\"\"\n",
    "    Calculate the scan duration in seconds based on AcquisitionTime and SeriesTime from a JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_path : str\n",
    "        The path to the JSON file containing scan metadata.\n",
    "    AcquisitionTime : str\n",
    "        The acquisition time in HH:MM:SS format.\n",
    "    SeriesTime : str\n",
    "        The series time in HH:MM:SS format.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The scan duration in seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        metadata = flatten_json(pd.read_json(f).to_dict(orient='records')[0])\n",
    "    \n",
    "    if AcquisitionTime is None:\n",
    "        AcquisitionTime = metadata.get('AcquisitionTime', None)\n",
    "        if AcquisitionTime is None:\n",
    "            raise ValueError(\"JSON file does not contain 'AcquisitionTime' field.\")\n",
    "    \n",
    "    if SeriesTime is None:\n",
    "        SeriesTime = metadata.get('SeriesTime', None)\n",
    "        if SeriesTime is None:\n",
    "            raise ValueError(\"JSON file does not contain 'SeriesTime' field.\")\n",
    "    \n",
    "    return time_to_seconds(AcquisitionTime) - time_to_seconds(SeriesTime)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'AcquisitionDuration', 'SeriesTime', 'AcquisitionTime', 'RepetitionTime', 'NumberOfVolumes'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "everything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
